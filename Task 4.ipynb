{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Benchmarking Fashion-MNIST with ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS 6316 Machine Learning - Department of Computer Science - University of Virginia\n",
    "\"The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\" - **Zalando Research, Github Repo.**\"\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "![Here's an example how the data looks (each class takes three-rows):](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)\n",
    "\n",
    "In this assignment, you will attempt to benchmarking the Fashion-MNIST using ANNs. You must use it to train some neural networks on TensorFlow and predict the final output of 10 classes. For deliverables, you must write code in Python and submit this Jupyter Notebook file (.ipynb) to earn a total of 100 pts. You will gain points depending on how you perform in the following sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. PRE-PROCESSING THE DATA (20 pts)\n",
    "\n",
    "You can load the Fashion MNIST directly from Tensorflow using the folliwng code:\n",
    "    tf.keras.datasets.fashion_mnist.load_data();\n",
    "\n",
    "Write some code to load the data file and take a quick look at the dataset, and output the following:\n",
    "- How big is your dataset? (regarding MB) - 147 MB\n",
    "- How many entries does it have? - 70000 entries\n",
    "- How many features does it have? - 784 features (pixel-28*28)\n",
    "- What are some basic statistics you can learn right away about this dataset? - its a very large dataset. If we attempt to use traditional ML techniques, it will run very slow given the high dimensionality of the data.\n",
    "\n",
    "**Large-scale Visualization:** Demonstrate that this dataset is indeed a complex and high dimensional worthy of an attempt on TensorFlow. Again, is there any non-linearly separation among the classes? Discover and plot out all features among the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oindrila\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# You might want to use the following package\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Your code goes here for this section.\n",
    "fashion_mnist_data=tf.keras.datasets.fashion_mnist;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('fashion-mnist_train.csv')\n",
    "test_data=pd.read_csv('fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big is your dataset? (in terms of MB)\n",
      "147 MB\n"
     ]
    }
   ],
   "source": [
    "print('How big is your dataset? (in terms of MB)')\n",
    "print ((os.path.getsize(\"fashion-mnist_train.csv\") >> 20) + (os.path.getsize(\"fashion-mnist_test.csv\") >> 20),'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 359.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 59.9 MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_data.iloc[:, 1:])\n",
    "y = tf.keras.utils.to_categorical(np.array(train_data.iloc[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1aa220b7c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize = (12, 4))\n",
    "sns.countplot(y.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classes = { 0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', \n",
    "          5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8 : 'Bag', 9 : 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_data=tf.keras.datasets.fashion_mnist;\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist_data.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(X_train[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given all the features and classes, we can see that classes like sneakers and ankle boots are not linearly separable. Similarly few other classes too are not linearly separable. Also with (28 * 28) pixel we can surely say that the dataset is complex and is high dimensional and hence worthy of using Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 2. CONSTRUCTION PHASE (25 pts)\n",
    "\n",
    "Define at least three networks with different structures: Ensure the input layer has the right number of inputs. The best structure often is found through a process of trial and error experimentation:\n",
    "- You may start with a fully connected network structure with two hidden layers.\n",
    "- You may try a few activation functions to see if they affect the performance.\n",
    "- You may use various optimizers to tweak the model parameters to minimize the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "n_inputs = 28*28 # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "reset_graph()\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 3. EXECUTION PHASE (30 pts)\n",
    "\n",
    "For each of the three models of your neural networks, open a TensorFlow session, define the number of epochs and size of the training batch (20 pts): For each model, you must compute the performance measures: Confusion Matrix and Class Accuracy.\n",
    "- Which one yields the best performance measure for your dataset?\n",
    "- You must be able to save the trained model and load it from disk to evaluate a test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.8 Val accuracy: 0.8392\n",
      "1 Batch accuracy: 0.8 Val accuracy: 0.8492\n",
      "2 Batch accuracy: 0.86 Val accuracy: 0.8592\n",
      "3 Batch accuracy: 0.96 Val accuracy: 0.852\n",
      "4 Batch accuracy: 0.9 Val accuracy: 0.86\n",
      "5 Batch accuracy: 0.9 Val accuracy: 0.8646\n",
      "6 Batch accuracy: 0.92 Val accuracy: 0.8718\n",
      "7 Batch accuracy: 0.9 Val accuracy: 0.8708\n",
      "8 Batch accuracy: 0.9 Val accuracy: 0.865\n",
      "9 Batch accuracy: 0.86 Val accuracy: 0.8742\n",
      "10 Batch accuracy: 0.86 Val accuracy: 0.8756\n",
      "11 Batch accuracy: 0.92 Val accuracy: 0.8788\n",
      "12 Batch accuracy: 0.88 Val accuracy: 0.8724\n",
      "13 Batch accuracy: 0.92 Val accuracy: 0.8788\n",
      "14 Batch accuracy: 0.86 Val accuracy: 0.8796\n",
      "15 Batch accuracy: 0.84 Val accuracy: 0.881\n",
      "16 Batch accuracy: 0.9 Val accuracy: 0.8802\n",
      "17 Batch accuracy: 0.94 Val accuracy: 0.8796\n",
      "18 Batch accuracy: 0.88 Val accuracy: 0.8856\n",
      "19 Batch accuracy: 1.0 Val accuracy: 0.8814\n",
      "20 Batch accuracy: 0.94 Val accuracy: 0.889\n",
      "21 Batch accuracy: 0.94 Val accuracy: 0.8874\n",
      "22 Batch accuracy: 0.96 Val accuracy: 0.8858\n",
      "23 Batch accuracy: 0.9 Val accuracy: 0.8874\n",
      "24 Batch accuracy: 0.94 Val accuracy: 0.8902\n",
      "25 Batch accuracy: 0.96 Val accuracy: 0.89\n",
      "26 Batch accuracy: 0.98 Val accuracy: 0.8902\n",
      "27 Batch accuracy: 0.9 Val accuracy: 0.8868\n",
      "28 Batch accuracy: 0.98 Val accuracy: 0.8844\n",
      "29 Batch accuracy: 0.98 Val accuracy: 0.8868\n",
      "30 Batch accuracy: 0.86 Val accuracy: 0.8924\n",
      "31 Batch accuracy: 0.96 Val accuracy: 0.891\n",
      "32 Batch accuracy: 0.94 Val accuracy: 0.889\n",
      "33 Batch accuracy: 0.96 Val accuracy: 0.8912\n",
      "34 Batch accuracy: 0.86 Val accuracy: 0.8942\n",
      "35 Batch accuracy: 0.98 Val accuracy: 0.8934\n",
      "36 Batch accuracy: 0.92 Val accuracy: 0.893\n",
      "37 Batch accuracy: 0.94 Val accuracy: 0.8954\n",
      "38 Batch accuracy: 0.94 Val accuracy: 0.8904\n",
      "39 Batch accuracy: 0.96 Val accuracy: 0.8936\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Batch accuracy:\", acc_batch, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\") # or better, use save_path\n",
    "    X_new_scaled = X_test\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8868"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[861,   0,  23,  19,   6,   1,  83,   0,   7,   0],\n",
       "       [  3, 971,   3,  17,   2,   0,   4,   0,   0,   0],\n",
       "       [ 17,   0, 856,   7,  74,   1,  44,   0,   1,   0],\n",
       "       [ 31,  10,  17, 880,  36,   0,  22,   0,   4,   0],\n",
       "       [  0,   1, 107,  29, 813,   0,  47,   0,   3,   0],\n",
       "       [  0,   0,   0,   1,   0, 969,   0,  19,   2,   9],\n",
       "       [143,   1, 108,  17,  66,   0, 652,   0,  13,   0],\n",
       "       [  0,   0,   0,   0,   0,  29,   0, 947,   0,  24],\n",
       "       [  4,   0,   9,   2,   5,   2,  10,   4, 964,   0],\n",
       "       [  0,   0,   0,   0,   0,  11,   1,  33,   0, 955]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Model- Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "n_hidden1 = 400\n",
    "n_hidden2 = 200\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Model- Execution Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.86 Val accuracy: 0.8426\n",
      "1 Batch accuracy: 0.74 Val accuracy: 0.853\n",
      "2 Batch accuracy: 0.86 Val accuracy: 0.8594\n",
      "3 Batch accuracy: 0.9 Val accuracy: 0.8594\n",
      "4 Batch accuracy: 0.86 Val accuracy: 0.863\n",
      "5 Batch accuracy: 0.92 Val accuracy: 0.867\n",
      "6 Batch accuracy: 0.92 Val accuracy: 0.877\n",
      "7 Batch accuracy: 0.88 Val accuracy: 0.8754\n",
      "8 Batch accuracy: 0.88 Val accuracy: 0.8716\n",
      "9 Batch accuracy: 0.84 Val accuracy: 0.8784\n",
      "10 Batch accuracy: 0.86 Val accuracy: 0.8794\n",
      "11 Batch accuracy: 0.92 Val accuracy: 0.8834\n",
      "12 Batch accuracy: 0.84 Val accuracy: 0.8792\n",
      "13 Batch accuracy: 0.94 Val accuracy: 0.8778\n",
      "14 Batch accuracy: 0.86 Val accuracy: 0.886\n",
      "15 Batch accuracy: 0.86 Val accuracy: 0.881\n",
      "16 Batch accuracy: 0.88 Val accuracy: 0.8854\n",
      "17 Batch accuracy: 0.92 Val accuracy: 0.8876\n",
      "18 Batch accuracy: 0.88 Val accuracy: 0.8864\n",
      "19 Batch accuracy: 0.96 Val accuracy: 0.8878\n",
      "20 Batch accuracy: 0.96 Val accuracy: 0.89\n",
      "21 Batch accuracy: 0.92 Val accuracy: 0.8914\n",
      "22 Batch accuracy: 0.96 Val accuracy: 0.8834\n",
      "23 Batch accuracy: 0.94 Val accuracy: 0.8888\n",
      "24 Batch accuracy: 0.9 Val accuracy: 0.8906\n",
      "25 Batch accuracy: 1.0 Val accuracy: 0.8928\n",
      "26 Batch accuracy: 0.98 Val accuracy: 0.8914\n",
      "27 Batch accuracy: 0.94 Val accuracy: 0.8902\n",
      "28 Batch accuracy: 0.96 Val accuracy: 0.8884\n",
      "29 Batch accuracy: 0.96 Val accuracy: 0.891\n",
      "30 Batch accuracy: 0.92 Val accuracy: 0.898\n",
      "31 Batch accuracy: 0.96 Val accuracy: 0.8902\n",
      "32 Batch accuracy: 0.96 Val accuracy: 0.8896\n",
      "33 Batch accuracy: 0.96 Val accuracy: 0.8928\n",
      "34 Batch accuracy: 0.92 Val accuracy: 0.8952\n",
      "35 Batch accuracy: 0.98 Val accuracy: 0.8962\n",
      "36 Batch accuracy: 0.94 Val accuracy: 0.8964\n",
      "37 Batch accuracy: 0.96 Val accuracy: 0.8982\n",
      "38 Batch accuracy: 0.96 Val accuracy: 0.896\n",
      "39 Batch accuracy: 0.96 Val accuracy: 0.899\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Batch accuracy:\", acc_batch, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./model2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model2.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./model2.ckpt\") # or better, use save_path\n",
    "    X_new_scaled = X_test\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8877"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[864,   2,  23,  18,   4,   2,  77,   0,  10,   0],\n",
       "       [  5, 970,   0,  20,   3,   0,   2,   0,   0,   0],\n",
       "       [ 17,   0, 873,  12,  63,   0,  34,   0,   1,   0],\n",
       "       [ 23,   8,  24, 886,  37,   0,  16,   0,   6,   0],\n",
       "       [  1,   1, 121,  24, 812,   0,  39,   0,   2,   0],\n",
       "       [  0,   0,   0,   0,   0, 965,   0,  19,   2,  14],\n",
       "       [133,   1, 117,  24,  75,   0, 639,   0,  11,   0],\n",
       "       [  0,   0,   0,   0,   0,  21,   0, 958,   0,  21],\n",
       "       [  5,   0,  11,   7,   3,   4,   7,   3, 960,   0],\n",
       "       [  1,   0,   0,   0,   0,  13,   0,  36,   0, 950]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd Model - Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "n_hidden1 = 350\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.elu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.elu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd Model - Execution Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.72 Val accuracy: 0.8444\n",
      "1 Batch accuracy: 0.74 Val accuracy: 0.8528\n",
      "2 Batch accuracy: 0.86 Val accuracy: 0.8566\n",
      "3 Batch accuracy: 0.9 Val accuracy: 0.855\n",
      "4 Batch accuracy: 0.9 Val accuracy: 0.859\n",
      "5 Batch accuracy: 0.92 Val accuracy: 0.862\n",
      "6 Batch accuracy: 0.94 Val accuracy: 0.8686\n",
      "7 Batch accuracy: 0.88 Val accuracy: 0.8684\n",
      "8 Batch accuracy: 0.9 Val accuracy: 0.8656\n",
      "9 Batch accuracy: 0.9 Val accuracy: 0.8706\n",
      "10 Batch accuracy: 0.86 Val accuracy: 0.875\n",
      "11 Batch accuracy: 0.92 Val accuracy: 0.8736\n",
      "12 Batch accuracy: 0.86 Val accuracy: 0.8692\n",
      "13 Batch accuracy: 0.9 Val accuracy: 0.8668\n",
      "14 Batch accuracy: 0.84 Val accuracy: 0.8762\n",
      "15 Batch accuracy: 0.84 Val accuracy: 0.874\n",
      "16 Batch accuracy: 0.88 Val accuracy: 0.8776\n",
      "17 Batch accuracy: 0.94 Val accuracy: 0.8796\n",
      "18 Batch accuracy: 0.84 Val accuracy: 0.8802\n",
      "19 Batch accuracy: 0.94 Val accuracy: 0.88\n",
      "20 Batch accuracy: 0.94 Val accuracy: 0.8832\n",
      "21 Batch accuracy: 0.92 Val accuracy: 0.882\n",
      "22 Batch accuracy: 0.92 Val accuracy: 0.88\n",
      "23 Batch accuracy: 0.9 Val accuracy: 0.8826\n",
      "24 Batch accuracy: 0.88 Val accuracy: 0.8804\n",
      "25 Batch accuracy: 0.98 Val accuracy: 0.8848\n",
      "26 Batch accuracy: 0.98 Val accuracy: 0.8866\n",
      "27 Batch accuracy: 0.9 Val accuracy: 0.8814\n",
      "28 Batch accuracy: 0.94 Val accuracy: 0.878\n",
      "29 Batch accuracy: 0.96 Val accuracy: 0.8842\n",
      "30 Batch accuracy: 0.88 Val accuracy: 0.889\n",
      "31 Batch accuracy: 0.96 Val accuracy: 0.884\n",
      "32 Batch accuracy: 0.94 Val accuracy: 0.883\n",
      "33 Batch accuracy: 0.96 Val accuracy: 0.8862\n",
      "34 Batch accuracy: 0.86 Val accuracy: 0.8886\n",
      "35 Batch accuracy: 1.0 Val accuracy: 0.8884\n",
      "36 Batch accuracy: 0.9 Val accuracy: 0.889\n",
      "37 Batch accuracy: 0.88 Val accuracy: 0.8916\n",
      "38 Batch accuracy: 0.94 Val accuracy: 0.8902\n",
      "39 Batch accuracy: 0.98 Val accuracy: 0.888\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Batch accuracy:\", acc_batch, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./model3.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model3.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./model3.ckpt\") # or better, use save_path\n",
    "    X_new_scaled = X_test\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8815"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[861,   0,  27,  21,   4,   1,  77,   0,   9,   0],\n",
       "       [  3, 968,   0,  23,   2,   0,   3,   0,   1,   0],\n",
       "       [ 16,   1, 867,  10,  49,   1,  54,   0,   2,   0],\n",
       "       [ 28,   9,  15, 886,  35,   1,  24,   0,   2,   0],\n",
       "       [  1,   1, 149,  27, 764,   0,  55,   0,   3,   0],\n",
       "       [  0,   0,   0,   1,   0, 951,   0,  30,   2,  16],\n",
       "       [139,   2, 110,  27,  58,   0, 653,   0,  11,   0],\n",
       "       [  0,   0,   0,   0,   0,  24,   0, 945,   0,  31],\n",
       "       [  6,   2,   8,   7,   2,   3,   6,   4, 962,   0],\n",
       "       [  0,   0,   0,   0,   0,   8,   1,  33,   0, 958]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 4. FINETUNING THE NETWORK (20 pts)\n",
    "\n",
    "You may be able to compare the performance of your method agaist other ML methods below:\n",
    "http://fashion-mnist.s3-website.eu-central-1.amazonaws.com\n",
    "\n",
    "To improve the performance of your ANN, you can use grid search with cross-validation to find the right set of hyperparameters, but that would take a lot of times (days, sometimes weeks). Therefore, you must make some decision of which reasonable values for each hyperparameter, so that you can restrict the search space. Here's a few decision about the network you have to made and justify:\n",
    "\n",
    "- The number of hidden layers. Why did you pick this many?\n",
    "- The number of neurons per hidden layers. Provide some justifiable reasons\n",
    "- Which activation functions need to be used? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "n_hidden1 = 400\n",
    "n_hidden2 = 200\n",
    "n_outputs = 10\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.8 Val accuracy: 0.8608\n",
      "1 Batch accuracy: 0.92 Val accuracy: 0.8744\n",
      "2 Batch accuracy: 0.86 Val accuracy: 0.8852\n",
      "3 Batch accuracy: 0.84 Val accuracy: 0.8858\n",
      "4 Batch accuracy: 0.94 Val accuracy: 0.8896\n",
      "5 Batch accuracy: 0.92 Val accuracy: 0.8876\n",
      "6 Batch accuracy: 0.86 Val accuracy: 0.8918\n",
      "7 Batch accuracy: 0.96 Val accuracy: 0.8826\n",
      "8 Batch accuracy: 0.94 Val accuracy: 0.8922\n",
      "9 Batch accuracy: 0.88 Val accuracy: 0.8934\n",
      "10 Batch accuracy: 0.92 Val accuracy: 0.8948\n",
      "11 Batch accuracy: 0.92 Val accuracy: 0.8968\n",
      "12 Batch accuracy: 0.88 Val accuracy: 0.8968\n",
      "13 Batch accuracy: 0.9 Val accuracy: 0.8966\n",
      "14 Batch accuracy: 0.96 Val accuracy: 0.8998\n",
      "15 Batch accuracy: 0.94 Val accuracy: 0.8962\n",
      "16 Batch accuracy: 1.0 Val accuracy: 0.8988\n",
      "17 Batch accuracy: 0.94 Val accuracy: 0.9014\n",
      "18 Batch accuracy: 0.94 Val accuracy: 0.8932\n",
      "19 Batch accuracy: 0.94 Val accuracy: 0.9\n",
      "20 Batch accuracy: 0.96 Val accuracy: 0.9\n",
      "21 Batch accuracy: 0.94 Val accuracy: 0.8994\n",
      "22 Batch accuracy: 1.0 Val accuracy: 0.8988\n",
      "23 Batch accuracy: 0.96 Val accuracy: 0.8998\n",
      "24 Batch accuracy: 0.98 Val accuracy: 0.901\n",
      "25 Batch accuracy: 0.96 Val accuracy: 0.8944\n",
      "26 Batch accuracy: 0.92 Val accuracy: 0.909\n",
      "27 Batch accuracy: 0.94 Val accuracy: 0.8998\n",
      "28 Batch accuracy: 0.92 Val accuracy: 0.8992\n",
      "29 Batch accuracy: 1.0 Val accuracy: 0.8986\n",
      "30 Batch accuracy: 1.0 Val accuracy: 0.8962\n",
      "31 Batch accuracy: 0.94 Val accuracy: 0.8976\n",
      "32 Batch accuracy: 0.98 Val accuracy: 0.9016\n",
      "33 Batch accuracy: 0.96 Val accuracy: 0.9\n",
      "34 Batch accuracy: 0.96 Val accuracy: 0.9046\n",
      "35 Batch accuracy: 0.94 Val accuracy: 0.8978\n",
      "36 Batch accuracy: 0.98 Val accuracy: 0.9036\n",
      "37 Batch accuracy: 0.98 Val accuracy: 0.8998\n",
      "38 Batch accuracy: 1.0 Val accuracy: 0.9002\n",
      "39 Batch accuracy: 0.98 Val accuracy: 0.902\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Batch accuracy:\", acc_batch, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\") # or better, use save_path\n",
    "    X_new_scaled = X_test\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8951"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 5. OUTLOOK (5 pts)\n",
    "\n",
    "Plan for the outlook of your system: This will lead to the direction of your future project:\n",
    "- Did your neural network outperform other \"traditional ML technique? Why/why not?\n",
    "- Does your model work well for the future? If not, which model should be further investigated?\n",
    "- Do you satisfy with your system? What do you think needed to improve?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Answers\n",
    "- Did your neural network outperform other: My neural network performed better than 90% of the traditional ML techniques. The reason might be the different parameters, the large size of the data, better scaling hence better for image classification, better with large number of features and also faster.\n",
    "- Does your model work well for the future? If not, which model should be further investigated? - It may not work well for future. CNN and RNN may outperform and have an incredible accuracy\n",
    "- Are you satisfy with your system? What do you think needed to improve? - I'm moderately satisfied with this model. However it could be improved by using other type of Optimizers and activation functions as there are many."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - \n",
    "### NEED HELP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you get stuck in any step in the process, you may find some useful information from:\n",
    "\n",
    " * Consult my lectures and/or the textbook\n",
    " * Talk to the TA, they are available and there to help you during [office hour](https://docs.google.com/document/d/15qB84xjaS-uRJmfKmmQuCz38bLMFaoqdbuRLoZEdOYI/edit#heading=h.72k1pvft525n)\n",
    " * Come talk to me or email me <nn4pj@virginia.edu> with subject starting \"CS6316 Assignment 3:...\".\n",
    " * More on the Fashion-MNIST to be found here: https://hanxiao.github.io/2018/09/28/Fashion-MNIST-Year-In-Review/\n",
    "\n",
    "Best of luck and have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
